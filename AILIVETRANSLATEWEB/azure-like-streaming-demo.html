<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Azure-like Voice Activity Detection Demo</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }
        .container {
            background: rgba(255,255,255,0.1);
            padding: 30px;
            border-radius: 15px;
            backdrop-filter: blur(10px);
        }
        .status-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        .status-card {
            background: rgba(255,255,255,0.1);
            padding: 20px;
            border-radius: 10px;
            border: 1px solid rgba(255,255,255,0.2);
        }
        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
        }
        .status-active { background: #4CAF50; }
        .status-inactive { background: #f44336; }
        .status-warning { background: #ff9800; }
        .controls {
            text-align: center;
            margin: 30px 0;
        }
        button {
            background: #4CAF50;
            color: white;
            border: none;
            padding: 15px 30px;
            font-size: 16px;
            border-radius: 25px;
            cursor: pointer;
            margin: 10px;
            transition: all 0.3s;
        }
        button:hover {
            background: #45a049;
            transform: translateY(-2px);
        }
        button:disabled {
            background: #666;
            cursor: not-allowed;
            transform: none;
        }
        .speech-indicator {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            margin: 20px auto;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 24px;
            transition: all 0.3s;
        }
        .speech-silent {
            background: rgba(255,255,255,0.1);
            border: 2px solid rgba(255,255,255,0.3);
        }
        .speech-detected {
            background: #4CAF50;
            border: 2px solid #2E7D32;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        .log-container {
            background: rgba(0,0,0,0.3);
            padding: 20px;
            border-radius: 10px;
            max-height: 300px;
            overflow-y: auto;
            font-family: monospace;
            font-size: 12px;
            margin: 20px 0;
        }
        .transcription {
            background: rgba(255,255,255,0.1);
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            min-height: 60px;
        }
        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        .metric {
            text-align: center;
            background: rgba(255,255,255,0.1);
            padding: 15px;
            border-radius: 8px;
        }
        .metric-value {
            font-size: 24px;
            font-weight: bold;
            display: block;
        }
        .metric-label {
            font-size: 12px;
            opacity: 0.8;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Azure-like Voice Activity Detection Demo</h1>
        <p>This demo showcases intelligent voice activity detection and continuous audio streaming, mimicking Azure Speech Service behavior.</p>
        
        <!-- Speech Indicator -->
        <div class="speech-indicator speech-silent" id="speechIndicator">
            üîï
        </div>

        <!-- Status Grid -->
        <div class="status-grid">
            <div class="status-card">
                <h3>üé§ VAD Status</h3>
                <div>
                    <span class="status-indicator status-inactive" id="vadStatus"></span>
                    <span id="vadStatusText">Not Initialized</span>
                </div>
                <div style="margin-top: 10px;">
                    <small>Positive Threshold: <span id="vadThreshold">0.8</span></small><br>
                    <small>Segments Processed: <span id="vadSegments">0</span></small>
                </div>
            </div>
            
            <div class="status-card">
                <h3>üéµ Streaming Status</h3>
                <div>
                    <span class="status-indicator status-inactive" id="streamStatus"></span>
                    <span id="streamStatusText">Not Started</span>
                </div>
                <div style="margin-top: 10px;">
                    <small>Sample Rate: <span id="streamRate">16000 Hz</span></small><br>
                    <small>Buffer Size: <span id="streamBuffer">4096</span></small>
                </div>
            </div>
            
            <div class="status-card">
                <h3>üåê WebSocket Status</h3>
                <div>
                    <span class="status-indicator status-inactive" id="wsStatus"></span>
                    <span id="wsStatusText">Disconnected</span>
                </div>
                <div style="margin-top: 10px;">
                    <small>Server: <span id="wsServer">ws://localhost:3001/ws</span></small><br>
                    <small>Messages Sent: <span id="wsMessages">0</span></small>
                </div>
            </div>
        </div>

        <!-- Audio Metrics -->
        <div class="metrics-grid">
            <div class="metric">
                <span class="metric-value" id="audioLevel">0</span>
                <span class="metric-label">Audio Level</span>
            </div>
            <div class="metric">
                <span class="metric-value" id="speechConfidence">0%</span>
                <span class="metric-label">Speech Confidence</span>
            </div>
            <div class="metric">
                <span class="metric-value" id="processingTime">0ms</span>
                <span class="metric-label">Processing Time</span>
            </div>
            <div class="metric">
                <span class="metric-value" id="audioSegments">0</span>
                <span class="metric-label">Audio Segments</span>
            </div>
        </div>

        <!-- Controls -->
        <div class="controls">
            <button id="initBtn" onclick="initializeServices()">Initialize VAD</button>
            <button id="startBtn" onclick="startListening()" disabled>Start Listening</button>
            <button id="stopBtn" onclick="stopListening()" disabled>Stop Listening</button>
            <button id="testBtn" onclick="testConnection()">Test WebSocket</button>
        </div>

        <!-- Transcription Display -->
        <div class="transcription">
            <h3>üìù Real-time Transcription</h3>
            <div id="transcriptionOutput">Transcription will appear here when speech is detected...</div>
        </div>

        <!-- Log Container -->
        <div class="log-container" id="logContainer">
            <strong>System Logs:</strong><br>
        </div>
    </div>

    <!-- Load VAD Library -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/bundle.min.js"></script>

    <script>
        // Global state
        let vadService = null;
        let streamingService = null;
        let websocket = null;
        let isListening = false;
        let speechCount = 0;
        let messageCount = 0;

        // Log function
        function log(message, level = 'info') {
            const timestamp = new Date().toLocaleTimeString();
            const logContainer = document.getElementById('logContainer');
            const color = level === 'error' ? '#f44336' : level === 'warning' ? '#ff9800' : '#4CAF50';
            logContainer.innerHTML += `<div style="color: ${color};">[${timestamp}] ${message}</div>`;
            logContainer.scrollTop = logContainer.scrollHeight;
            console.log(`[${level.toUpperCase()}] ${message}`);
        }

        // Update UI indicators
        function updateStatus(type, active, text) {
            const indicator = document.getElementById(type + 'Status');
            const statusText = document.getElementById(type + 'StatusText');
            
            indicator.className = `status-indicator status-${active ? 'active' : 'inactive'}`;
            statusText.textContent = text;
        }

        function updateSpeechIndicator(isDetected) {
            const indicator = document.getElementById('speechIndicator');
            if (isDetected) {
                indicator.className = 'speech-indicator speech-detected';
                indicator.textContent = 'üéôÔ∏è';
            } else {
                indicator.className = 'speech-indicator speech-silent';
                indicator.textContent = 'üîï';
            }
        }

        function updateMetric(id, value) {
            document.getElementById(id).textContent = value;
        }

        // Initialize services
        async function initializeServices() {
            try {
                log('üé§ Initializing Voice Activity Detection...');
                document.getElementById('initBtn').disabled = true;

                // Initialize VAD with Azure-like settings
                vadService = await vad.MicVAD.new({
                    positiveSpeechThreshold: 0.8,
                    negativeSpeechThreshold: 0.35,
                    preSpeechPadFrames: 1,
                    redemptionFrames: 8,
                    frameSamples: 1536,
                    minSpeechFrames: 3,

                    onSpeechStart: () => {
                        log('üéôÔ∏è Speech detected - processing started');
                        updateSpeechIndicator(true);
                        updateMetric('speechConfidence', '85%');
                    },

                    onSpeechEnd: (audio) => {
                        const duration = (audio.length / 16000).toFixed(2);
                        log(`üéôÔ∏è Speech ended - ${audio.length} samples (${duration}s)`);
                        updateSpeechIndicator(false);
                        
                        speechCount++;
                        updateMetric('audioSegments', speechCount);
                        
                        // Send to WebSocket if connected
                        if (websocket && websocket.readyState === WebSocket.OPEN) {
                            sendAudioToServer(audio);
                        }
                    },

                    onVADMisfire: () => {
                        log('‚ö†Ô∏è VAD misfire detected', 'warning');
                    }
                });

                // Initialize WebSocket connection
                initializeWebSocket();

                updateStatus('vad', true, 'Initialized');
                document.getElementById('startBtn').disabled = false;
                log('‚úÖ VAD initialized successfully');

            } catch (error) {
                log(`‚ùå Failed to initialize VAD: ${error.message}`, 'error');
                document.getElementById('initBtn').disabled = false;
            }
        }

        function initializeWebSocket() {
            try {
                websocket = new WebSocket('ws://localhost:3001/ws');
                
                websocket.onopen = () => {
                    log('üåê WebSocket connected');
                    updateStatus('ws', true, 'Connected');
                    
                    // Send initialization message
                    websocket.send(JSON.stringify({
                        type: 'init',
                        language: 'en-US',
                        targetLanguage: 'ar',
                        clientSideTranslation: true,
                        realTimeMode: true
                    }));
                };

                websocket.onmessage = (event) => {
                    try {
                        const data = JSON.parse(event.data);
                        handleServerMessage(data);
                    } catch (error) {
                        log(`‚ùå Error parsing server message: ${error.message}`, 'error');
                    }
                };

                websocket.onclose = () => {
                    log('üåê WebSocket disconnected', 'warning');
                    updateStatus('ws', false, 'Disconnected');
                };

                websocket.onerror = (error) => {
                    log(`‚ùå WebSocket error: ${error}`, 'error');
                    updateStatus('ws', false, 'Error');
                };

            } catch (error) {
                log(`‚ùå Failed to initialize WebSocket: ${error.message}`, 'error');
            }
        }

        function handleServerMessage(data) {
            switch (data.type) {
                case 'partial':
                    updateTranscription(`[Partial] ${data.text}`, false);
                    break;
                case 'final':
                    updateTranscription(`[Final] ${data.text}`, true);
                    break;
                case 'translation':
                    updateTranscription(`[Translation] ${data.translation}`, true);
                    break;
                case 'warning':
                    log(`‚ö†Ô∏è Server warning: ${data.message}`, 'warning');
                    break;
                case 'error':
                    log(`‚ùå Server error: ${data.message}`, 'error');
                    break;
                default:
                    log(`üì• Server message: ${data.type}`);
            }
        }

        function updateTranscription(text, isFinal) {
            const output = document.getElementById('transcriptionOutput');
            if (isFinal) {
                output.innerHTML += `<div style="margin: 5px 0; padding: 5px; background: rgba(255,255,255,0.1); border-radius: 5px;">${text}</div>`;
            } else {
                // Update or add partial result
                const partials = output.querySelectorAll('.partial');
                if (partials.length > 0) {
                    partials[partials.length - 1].textContent = text;
                } else {
                    output.innerHTML += `<div class="partial" style="font-style: italic; opacity: 0.7;">${text}</div>`;
                }
            }
            output.scrollTop = output.scrollHeight;
        }

        function sendAudioToServer(audioData) {
            if (!websocket || websocket.readyState !== WebSocket.OPEN) {
                log('‚ùå WebSocket not connected', 'error');
                return;
            }

            try {
                // Convert Float32Array to PCM Int16Array
                const pcm16 = new Int16Array(audioData.length);
                for (let i = 0; i < audioData.length; i++) {
                    const sample = Math.max(-1, Math.min(1, audioData[i]));
                    pcm16[i] = Math.round(sample * 32767);
                }

                // Convert to base64
                const buffer = new ArrayBuffer(pcm16.length * 2);
                const view = new DataView(buffer);
                for (let i = 0; i < pcm16.length; i++) {
                    view.setInt16(i * 2, pcm16[i], true);
                }
                
                const uint8Array = new Uint8Array(buffer);
                let binary = '';
                for (let i = 0; i < uint8Array.length; i++) {
                    binary += String.fromCharCode(uint8Array[i]);
                }
                const base64Audio = btoa(binary);

                const audioMessage = {
                    type: 'audio',
                    data: base64Audio,
                    format: 'audio/pcm',
                    timestamp: Date.now(),
                    size: audioData.length
                };

                websocket.send(JSON.stringify(audioMessage));
                messageCount++;
                updateMetric('wsMessages', messageCount);
                log(`üì§ Sent audio to server: ${audioData.length} samples`);

            } catch (error) {
                log(`‚ùå Error sending audio: ${error.message}`, 'error');
            }
        }

        async function startListening() {
            if (!vadService) {
                log('‚ùå VAD not initialized', 'error');
                return;
            }

            try {
                log('üéôÔ∏è Starting voice activity detection...');
                await vadService.start();
                
                isListening = true;
                updateStatus('stream', true, 'Listening');
                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                log('‚úÖ VAD listening started');

            } catch (error) {
                log(`‚ùå Failed to start listening: ${error.message}`, 'error');
            }
        }

        async function stopListening() {
            if (!vadService || !isListening) {
                return;
            }

            try {
                log('üõë Stopping voice activity detection...');
                await vadService.pause();
                
                isListening = false;
                updateStatus('stream', false, 'Stopped');
                updateSpeechIndicator(false);
                document.getElementById('startBtn').disabled = false;
                document.getElementById('stopBtn').disabled = true;
                log('‚úÖ VAD listening stopped');

            } catch (error) {
                log(`‚ùå Error stopping VAD: ${error.message}`, 'error');
            }
        }

        function testConnection() {
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.send(JSON.stringify({ type: 'ping', timestamp: Date.now() }));
                log('üèì Ping sent to server');
            } else {
                log('‚ùå WebSocket not connected', 'error');
            }
        }

        // Cleanup on page unload
        window.addEventListener('beforeunload', async () => {
            if (vadService) {
                await vadService.destroy();
            }
            if (websocket) {
                websocket.close();
            }
        });

        // Initialize UI
        log('üöÄ Azure-like VAD Demo loaded - Click Initialize to begin');
        updateMetric('vadThreshold', '0.8');
        updateMetric('streamRate', '16000 Hz');
        updateMetric('streamBuffer', '1536');
    </script>
</body>
</html> 