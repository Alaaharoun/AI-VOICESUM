// Enhanced Server Logging Script
const fs = require('fs');
const path = require('path');

console.log('ğŸ”§ Enhancing server logging...');

// Read the current server file
const serverPath = path.join(__dirname, '..', 'azure-server.js');
let serverContent = fs.readFileSync(serverPath, 'utf8');

// Add enhanced logging to WebSocket message handling
const enhancedLogging = `
    ws.on('message', (data) => {
      try {
        console.log('[WebSocket] ğŸ“¥ Received message from client');
        console.log('[WebSocket] ğŸ“Š Message type:', typeof data);
        console.log('[WebSocket] ğŸ“ Message size:', data.length || data.byteLength || 'unknown');
        
        // Check if it's a JSON message (init, language_update, etc.)
        if (typeof data === 'string') {
          const message = JSON.parse(data);
          console.log('[WebSocket] ğŸ“‹ Parsed JSON message:', message.type);
          console.log('[WebSocket] ğŸ” Message details:', JSON.stringify(message, null, 2));
          
          if (message.type === 'init') {
            console.log('[WebSocket] ğŸ”§ Processing init message...');
            console.log('[WebSocket] ğŸŒ Source language:', message.language);
            console.log('[WebSocket] ğŸ¯ Target language:', message.targetLanguage);
            console.log('[WebSocket] ğŸ”„ Auto detection:', message.autoDetection);
            
            // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù‚Ø¨Ù„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ‡ÙŠØ¦Ø©
            try {
              recognizer.stopContinuousRecognitionAsync();
              recognizer.close();
              pushStream.close();
              console.log('[Azure] ğŸ§¹ Cleaned up previous session before reinitialization');
            } catch (error) {
              console.log('[Azure] âš ï¸ No previous session to cleanup:', error.message);
            }
            
            // Handle auto detection or specific language
            const rawLanguage = message.language;
            const autoDetection = message.autoDetection || false;
            
            let language;
            if (autoDetection || !rawLanguage) {
              // Use auto detection - Azure will automatically detect from 10+ languages
              language = null;
              console.log('[Azure] ğŸ”§ Initializing with AUTO DETECTION (no specific language)');
            } else {
              // Use specific language
              language = validateAzureLanguage(rawLanguage);
              console.log('[Azure] ğŸ”§ Initializing with specific language:', rawLanguage, 'â†’', language);
            }
            
            // Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¹ Ø§Ù„Ù„ØºØ© Ø§Ù„ØµØ­ÙŠØ­Ø©
            // Ø§Ø³ØªØ®Ø¯Ø§Ù… 16kHz Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† 48kHz Ù„ØªØ¬Ù†Ø¨ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚
            pushStream = speechsdk.AudioInputStream.createPushStream(speechsdk.AudioStreamFormat.getWaveFormatPCM(16000, 16, 1));
            audioConfig = speechsdk.AudioConfig.fromStreamInput(pushStream);
            speechConfig = speechsdk.SpeechConfig.fromSubscription(AZURE_SPEECH_KEY, AZURE_SPEECH_REGION);
            
            // Set language only if not using auto detection
            if (language) {
              speechConfig.speechRecognitionLanguage = language;
            } else {
              // For auto detection, don't set a specific language
              // Azure will automatically detect from supported languages
              console.log('[Azure] ğŸ¯ Auto detection enabled - Azure will detect language automatically');
            }
            
            // ØªØ­Ø³ÙŠÙ†Ø§Øª Azure Ù„Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ chunks ÙƒØ¨ÙŠØ±Ø©
            speechConfig.setProperty(speechsdk.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, "15000");
            speechConfig.setProperty(speechsdk.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, "10000");
            speechConfig.setProperty(speechsdk.PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse, "true");
            
            recognizer = new speechsdk.SpeechRecognizer(speechConfig, audioConfig);
            
            // Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³ØªÙ…Ø¹ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø¯
            recognizer.recognizing = (s, e) => {
              console.log(\`[Azure Speech] ğŸ”„ Partial result: "\${e.result.text}"\`);
              if (e.result.text && e.result.text.trim()) {
                console.log(\`[Azure Speech] ğŸ“¤ Sending partial transcription: "\${e.result.text}"\`);
                ws.send(JSON.stringify({ type: 'transcription', text: e.result.text }));
              }
            };
            
            recognizer.recognized = (s, e) => {
              if (e.result.reason === speechsdk.ResultReason.RecognizedSpeech) {
                console.log(\`[Azure Speech] âœ… Final result: "\${e.result.text}"\`);
                if (e.result.text && e.result.text.trim()) {
                  console.log(\`[Azure Speech] ğŸ“¤ Sending final transcription: "\${e.result.text}"\`);
                  ws.send(JSON.stringify({ type: 'final', text: e.result.text }));
                } else {
                  console.log('[Azure Speech] Empty final result, not sending');
                }
              }
            };
            
            recognizer.canceled = (s, e) => {
              console.log('[Azure Speech] âŒ Recognition canceled:', e.errorDetails);
              ws.send(JSON.stringify({ type: 'error', error: e.errorDetails }));
            };
            
            recognizer.sessionStopped = (s, e) => {
              console.log('[Azure Speech] ğŸ›‘ Session stopped');
              ws.send(JSON.stringify({ type: 'done' }));
            };
            
            // Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯
            recognizer.startContinuousRecognitionAsync(
              () => {
                if (language) {
                  console.log('[Azure Speech] âœ… Recognition started successfully with language:', language);
                  ws.send(JSON.stringify({ type: 'status', message: 'Initialized with language: ' + language }));
                } else {
                  console.log('[Azure Speech] âœ… Recognition started successfully with AUTO DETECTION');
                  ws.send(JSON.stringify({ type: 'status', message: 'Initialized with AUTO DETECTION - Azure will detect language automatically' }));
                }
              },
              (error) => {
                console.log('[Azure Speech] âŒ Failed to start recognition:', error);
                ws.send(JSON.stringify({ type: 'error', error: 'Failed to start recognition: ' + error }));
              }
            );
          } else if (message.type === 'audio') {
            // Handle audio data
            console.log('[WebSocket] ğŸµ Processing audio message...');
            console.log('[WebSocket] ğŸ“Š Audio format:', message.format);
            console.log('[WebSocket] ğŸ“ Audio data length:', message.data ? message.data.length : 'undefined');
            
            const audioData = message.data;
            if (audioData) {
              const audioBuffer = Buffer.from(audioData, 'base64');
              console.log('[WebSocket] âœ… Audio data decoded successfully');
              console.log('[WebSocket] ğŸ“ Decoded audio buffer size:', audioBuffer.length, 'bytes');
              console.log('[WebSocket] ğŸµ Audio format from client:', message.format);
              console.log('[WebSocket] ğŸŒ Source language:', message.sourceLanguage || 'not specified');
              console.log('[WebSocket] ğŸ¯ Target language:', message.targetLanguage || 'not specified');
              
              // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙŠØ³Øª ÙØ§Ø±ØºØ© Ø£Ùˆ Ù‚Ø¯ÙŠÙ…Ø© Ø¬Ø¯Ø§Ù‹
              if (audioBuffer.length > 0) {
                console.log('[WebSocket] ğŸ“¤ Writing audio buffer to Azure push stream...');
                pushStream.write(audioBuffer);
                console.log('[WebSocket] âœ… Audio buffer written to Azure stream');
              } else {
                console.log('[WebSocket] âš ï¸ Skipping empty audio buffer');
              }
            } else {
              console.log('[WebSocket] âŒ No audio data in message');
            }
          } else {
            console.log('[WebSocket] â“ Unknown message type:', message.type);
          }
        } else {
          // Handle raw audio data (fallback)
          console.log('[WebSocket] ğŸ“¥ Received raw audio data (fallback)');
          console.log('[WebSocket] ğŸ“Š Data type:', typeof data);
          console.log('[WebSocket] ğŸ“ Data size:', data.length || data.byteLength || 'unknown');
          
          // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙŠØ³Øª ÙØ§Ø±ØºØ©
          if (data && (data.length > 0 || data.byteLength > 0)) {
            console.log('[WebSocket] ğŸ“¤ Writing raw audio data to Azure push stream...');
            if (data instanceof Buffer) {
              pushStream.write(data);
            } else if (data instanceof ArrayBuffer) {
              pushStream.write(Buffer.from(data));
            } else {
              pushStream.write(Buffer.from(data));
            }
            console.log('[WebSocket] âœ… Raw audio data written to Azure stream');
          } else {
            console.log('[WebSocket] âš ï¸ Skipping empty raw audio data');
          }
        }
      } catch (error) {
        console.error('[WebSocket] âŒ Error processing message:', error);
        console.error('[WebSocket] âŒ Error details:', error.message);
        console.error('[WebSocket] âŒ Error stack:', error.stack);
      }
    });
`;

// Replace the existing message handler with enhanced logging
const messageHandlerPattern = /ws\.on\('message', \(data\) => \{[\s\S]*?\}\);[\s\S]*?\} else \{[\s\S]*?\}[\s\S]*?\} catch \(error\) \{[\s\S]*?\}/;
const replacement = enhancedLogging;

if (messageHandlerPattern.test(serverContent)) {
  serverContent = serverContent.replace(messageHandlerPattern, replacement);
  console.log('âœ… Enhanced logging added to server');
} else {
  console.log('âŒ Could not find message handler pattern in server file');
}

// Add connection logging
const connectionLogging = `
    wsServer.on('connection', (ws) => {
      console.log('[WebSocket] ğŸ”— New client connected');
      console.log('[WebSocket] ğŸ“Š Client IP:', ws._socket.remoteAddress);
      console.log('[WebSocket] ğŸ“Š Client port:', ws._socket.remotePort);
      console.log('[WebSocket] ğŸ“Š User agent:', ws._socket.remoteAddress ? 'Unknown' : 'Direct connection');
      
      try {
        const AZURE_SPEECH_KEY = process.env.AZURE_SPEECH_KEY;
        const AZURE_SPEECH_REGION = process.env.AZURE_SPEECH_REGION;
        
        console.log('[WebSocket] ğŸ”‘ Checking Azure credentials...');
        console.log('[WebSocket] Key present:', !!AZURE_SPEECH_KEY);
        console.log('[WebSocket] Region present:', !!AZURE_SPEECH_REGION);
        
        if (!AZURE_SPEECH_KEY || !AZURE_SPEECH_REGION) {
          console.log('[WebSocket] âŒ Azure credentials missing!');
          ws.send(JSON.stringify({ type: 'error', error: 'Azure Speech credentials missing!' }));
          ws.close();
          return;
        }
        
        console.log('[WebSocket] âœ… Azure credentials OK, proceeding...');
`;

// Replace the connection handler
const connectionPattern = /wsServer\.on\('connection', \(ws\) => \{[\s\S]*?console\.log\('\[WebSocket\] ğŸ”— New client connected'\);[\s\S]*?try \{[\s\S]*?const AZURE_SPEECH_KEY = process\.env\.AZURE_SPEECH_KEY;[\s\S]*?console\.log\('\[WebSocket\] âœ… Azure credentials OK, proceeding\.\.\.'\);/;
const connectionReplacement = connectionLogging;

if (connectionPattern.test(serverContent)) {
  serverContent = serverContent.replace(connectionPattern, connectionReplacement);
  console.log('âœ… Enhanced connection logging added to server');
} else {
  console.log('âŒ Could not find connection handler pattern in server file');
}

// Write the improved server file
const improvedServerPath = path.join(__dirname, '..', 'azure-server-enhanced.js');
fs.writeFileSync(improvedServerPath, serverContent);

console.log('âœ… Enhanced server file created:', improvedServerPath);
console.log('ğŸ“‹ Changes made:');
console.log('   - Enhanced WebSocket message logging');
console.log('   - Added detailed audio data processing logs');
console.log('   - Added connection information logging');
console.log('   - Added error handling with detailed stack traces');
console.log('');
console.log('ğŸš€ To use the enhanced server:');
console.log('   1. Stop the current server');
console.log('   2. Replace azure-server.js with azure-server-enhanced.js');
console.log('   3. Restart the server');
console.log('   4. Test with the diagnostic tool'); 