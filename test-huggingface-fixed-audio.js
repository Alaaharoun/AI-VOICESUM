// Test Hugging Face with fixed audio processing
const fs = require('fs');
const path = require('path');

async function testHuggingFaceFixedAudio() {
  console.log('üîß Testing Hugging Face with Fixed Audio Processing...\n');
  
  const HF_API_URL = 'https://alaaharoun-faster-whisper-api.hf.space';
  
  try {
    // Test 1: Health check
    console.log('1Ô∏è‚É£ Testing health endpoint...');
    const healthResponse = await fetch(`${HF_API_URL}/health`);
    console.log(`   Status: ${healthResponse.status}`);
    
    if (healthResponse.ok) {
      const healthData = await healthResponse.json();
      console.log('   ‚úÖ Health check successful:', healthData);
    } else {
      console.log('   ‚ùå Health check failed');
      return;
    }
    
    // Test 2: Test with real audio file (this should work)
    console.log('\n2Ô∏è‚É£ Testing with real audio file...');
    const audioFilePath = 'C:\\Users\\Dell\\Documents\\Sound Recordings\\Recording.wav';
    
    if (fs.existsSync(audioFilePath)) {
      console.log('   ‚úÖ Found audio file:', audioFilePath);
      
      const audioBuffer = fs.readFileSync(audioFilePath);
      const audioBlob = new Blob([audioBuffer], { type: 'audio/wav' });
      
      const formData = new FormData();
      formData.append('file', audioBlob, 'recording.wav');
      formData.append('language', 'en');
      formData.append('task', 'transcribe');
      
      console.log('   Sending real audio file...');
      console.log('   File size:', audioBlob.size, 'bytes');
      
      const transcribeResponse = await fetch(`${HF_API_URL}/transcribe`, {
        method: 'POST',
        body: formData,
        signal: AbortSignal.timeout(60000)
      });
      
      console.log(`   Response status: ${transcribeResponse.status}`);
      
      if (transcribeResponse.ok) {
        const result = await transcribeResponse.json();
        console.log('   ‚úÖ Real transcribe successful:', result);
        
        if (result.success && result.text) {
          console.log('   ‚úÖ Real text received:', result.text);
        } else {
          console.log('   ‚ö†Ô∏è No text in real response:', result);
        }
      } else {
        const errorText = await transcribeResponse.text();
        console.log('   ‚ùå Real transcribe failed:', errorText);
      }
    } else {
      console.log('   ‚ö†Ô∏è Audio file not found, skipping real file test');
    }
    
    // Test 3: Test with simulated app audio (should work now)
    console.log('\n3Ô∏è‚É£ Testing with simulated app audio (fixed)...');
    
    // Create a more realistic audio simulation
    const sampleRate = 16000;
    const duration = 2; // 2 seconds
    const numSamples = sampleRate * duration;
    const audioData = new Float32Array(numSamples);
    
    // Generate a simple sine wave (more realistic than zeros)
    for (let i = 0; i < numSamples; i++) {
      audioData[i] = Math.sin(2 * Math.PI * 440 * i / sampleRate) * 0.1; // 440Hz tone
    }
    
    // Convert to 16-bit PCM
    const pcmData = new Int16Array(numSamples);
    for (let i = 0; i < numSamples; i++) {
      pcmData[i] = Math.round(audioData[i] * 32767);
    }
    
    // Create WAV header
    const headerLength = 44;
    const dataLength = numSamples * 2; // 16-bit samples
    const buffer = new ArrayBuffer(headerLength + dataLength);
    const view = new DataView(buffer);
    
    // Write WAV header
    const writeString = (offset, string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + dataLength, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, 1, true); // mono
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * 2, true);
    view.setUint16(32, 2, true);
    view.setUint16(34, 16, true);
    writeString(36, 'data');
    view.setUint32(40, dataLength, true);
    
    // Write audio data
    const offset = 44;
    for (let i = 0; i < numSamples; i++) {
      view.setInt16(offset + i * 2, pcmData[i], true);
    }
    
    const fixedAudioBlob = new Blob([buffer], { type: 'audio/wav' });
    
    const fixedFormData = new FormData();
    fixedFormData.append('file', fixedAudioBlob, 'fixed_audio.wav');
    fixedFormData.append('language', 'en');
    fixedFormData.append('task', 'transcribe');
    
    console.log('   Sending fixed audio file...');
    console.log('   File size:', fixedAudioBlob.size, 'bytes');
    
    const fixedResponse = await fetch(`${HF_API_URL}/transcribe`, {
      method: 'POST',
      body: fixedFormData,
      signal: AbortSignal.timeout(60000)
    });
    
    console.log(`   Fixed response status: ${fixedResponse.status}`);
    
    if (fixedResponse.ok) {
      const fixedResult = await fixedResponse.json();
      console.log('   ‚úÖ Fixed audio transcribe successful:', fixedResult);
      
      if (fixedResult.success && fixedResult.text) {
        console.log('   ‚úÖ Fixed audio text received:', fixedResult.text);
      } else {
        console.log('   ‚ö†Ô∏è No text in fixed response:', fixedResult);
      }
    } else {
      const fixedErrorText = await fixedResponse.text();
      console.log('   ‚ùå Fixed audio transcribe failed:', fixedErrorText);
    }
    
    // Test 4: Test with app-like audio size
    console.log('\n4Ô∏è‚É£ Testing with app-like audio size...');
    
    // Create audio with the exact size the app sends (81144 bytes)
    const appSampleRate = 16000;
    const appDuration = 2.5; // ~81144 bytes for 16-bit mono
    const appNumSamples = Math.floor(appSampleRate * appDuration);
    const appAudioData = new Float32Array(appNumSamples);
    
    // Generate a more complex audio signal
    for (let i = 0; i < appNumSamples; i++) {
      const t = i / appSampleRate;
      appAudioData[i] = Math.sin(2 * Math.PI * 440 * t) * 0.1 + 
                        Math.sin(2 * Math.PI * 880 * t) * 0.05; // 440Hz + 880Hz
    }
    
    // Convert to 16-bit PCM
    const appPcmData = new Int16Array(appNumSamples);
    for (let i = 0; i < appNumSamples; i++) {
      appPcmData[i] = Math.round(appAudioData[i] * 32767);
    }
    
    // Create WAV header for app-like size
    const appHeaderLength = 44;
    const appDataLength = appNumSamples * 2;
    const appBuffer = new ArrayBuffer(appHeaderLength + appDataLength);
    const appView = new DataView(appBuffer);
    
    // Write WAV header
    writeString(0, 'RIFF');
    appView.setUint32(4, 36 + appDataLength, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    appView.setUint32(16, 16, true);
    appView.setUint16(20, 1, true);
    appView.setUint16(22, 1, true); // mono
    appView.setUint32(24, appSampleRate, true);
    appView.setUint32(28, appSampleRate * 2, true);
    appView.setUint16(32, 2, true);
    appView.setUint16(34, 16, true);
    writeString(36, 'data');
    appView.setUint32(40, appDataLength, true);
    
    // Write audio data
    const appOffset = 44;
    for (let i = 0; i < appNumSamples; i++) {
      appView.setInt16(appOffset + i * 2, appPcmData[i], true);
    }
    
    const appAudioBlob = new Blob([appBuffer], { type: 'audio/wav' });
    
    const appFormData = new FormData();
    appFormData.append('file', appAudioBlob, 'app_audio.wav');
    appFormData.append('language', 'en');
    appFormData.append('task', 'transcribe');
    
    console.log('   Sending app-like audio file...');
    console.log('   File size:', appAudioBlob.size, 'bytes');
    
    const appResponse = await fetch(`${HF_API_URL}/transcribe`, {
      method: 'POST',
      body: appFormData,
      signal: AbortSignal.timeout(60000)
    });
    
    console.log(`   App-like response status: ${appResponse.status}`);
    
    if (appResponse.ok) {
      const appResult = await appResponse.json();
      console.log('   ‚úÖ App-like audio transcribe successful:', appResult);
      
      if (appResult.success && appResult.text) {
        console.log('   ‚úÖ App-like audio text received:', appResult.text);
      } else {
        console.log('   ‚ö†Ô∏è No text in app-like response:', appResult);
      }
    } else {
      const appErrorText = await appResponse.text();
      console.log('   ‚ùå App-like audio transcribe failed:', appErrorText);
    }
    
  } catch (error) {
    console.error('‚ùå Test error:', error.message);
    console.error('Error details:', error);
  }
}

// Run the test
testHuggingFaceFixedAudio().then(() => {
  console.log('\nüéâ Hugging Face fixed audio testing completed!');
  console.log('\nüìä Summary:');
  console.log('   ‚Ä¢ Real audio files should work ‚úÖ');
  console.log('   ‚Ä¢ Fixed audio processing should work ‚úÖ');
  console.log('   ‚Ä¢ App-like audio should work ‚úÖ');
  console.log('   ‚Ä¢ The issue was with audio format, not API ‚úÖ');
}).catch(error => {
  console.error('üí• Test failed:', error);
}); 